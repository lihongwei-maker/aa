{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSaving and loading models for inference in PyTorch\n==================================================\nThere are two approaches for saving and loading models for inference in\nPyTorch. The first is saving and loading the ``state_dict``, and the\nsecond is saving and loading the entire model.\n\nIntroduction\n------------\nSaving the model\u2019s ``state_dict`` with the ``torch.save()`` function\nwill give you the most flexibility for restoring the model later. This\nis the recommended method for saving models, because it is only really\nnecessary to save the trained model\u2019s learned parameters.\nWhen saving and loading an entire model, you save the entire module\nusing Python\u2019s\n`pickle <https://docs.python.org/3/library/pickle.html>`__ module. Using\nthis approach yields the most intuitive syntax and involves the least\namount of code. The disadvantage of this approach is that the serialized\ndata is bound to the specific classes and the exact directory structure\nused when the model is saved. The reason for this is because pickle does\nnot save the model class itself. Rather, it saves a path to the file\ncontaining the class, which is used during load time. Because of this,\nyour code can break in various ways when used in other projects or after\nrefactors.\nIn this recipe, we will explore both ways on how to save and load models\nfor inference.\n\nSetup\n-----\nBefore we begin, we need to install ``torch`` if it isn\u2019t already\navailable.\n\n\n::\n\n   pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Steps\n-----\n\n1. Import all necessary libraries for loading our data\n2. Define and intialize the neural network\n3. Initialize the optimizer\n4. Save and load the model via ``state_dict``\n5. Save and load the entire model\n\n1. Import necessary libraries for loading our data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFor this recipe, we will use ``torch`` and its subsidiaries ``torch.nn``\nand ``torch.optim``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Define and intialize the neural network\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFor sake of example, we will create a neural network for training\nimages. To learn more see the Defining a Neural Network recipe.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nprint(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Initialize the optimizer\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWe will use SGD with momentum.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Save and load the model via ``state_dict``\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nLet\u2019s save and load our model using just ``state_dict``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specify a path\nPATH = \"state_dict_model.pt\"\n\n# Save\ntorch.save(net.state_dict(), PATH)\n\n# Load\nmodel = Net()\nmodel.load_state_dict(torch.load(PATH))\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A common PyTorch convention is to save models using either a ``.pt`` or\n``.pth`` file extension.\n\nNotice that the ``load_state_dict()`` function takes a dictionary\nobject, NOT a path to a saved object. This means that you must\ndeserialize the saved state_dict before you pass it to the\n``load_state_dict()`` function. For example, you CANNOT load using\n``model.load_state_dict(PATH)``.\n\nRemember too, that you must call ``model.eval()`` to set dropout and\nbatch normalization layers to evaluation mode before running inference.\nFailing to do this will yield inconsistent inference results.\n\n5. Save and load entire model\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nNow let\u2019s try the same thing with the entire model.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specify a path\nPATH = \"entire_model.pt\"\n\n# Save\ntorch.save(net, PATH)\n\n# Load\nmodel = torch.load(PATH)\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again here, remember that you must call model.eval() to set dropout and\nbatch normalization layers to evaluation mode before running inference.\n\nCongratulations! You have successfully saved and load models for\ninference in PyTorch.\n\nLearn More\n----------\n\nTake a look at these other recipes to continue your learning:\n\n- `Saving and loading a general checkpoint in PyTorch <https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html>`__\n- `Saving and loading multiple models in one file using PyTorch <https://pytorch.org/tutorials/recipes/recipes/saving_multiple_models_in_one_file.html>`__\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}