
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Customize Process Group Backends Using Cpp Extensions — PyTorch Tutorials 2.2.0+cu121 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css" rel="stylesheet" type="text/css"/>
<link href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom2.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="rpc_tutorial.html" rel="next" title="Getting Started with Distributed RPC Framework"/>
<link href="FSDP_adavnced_tutorial.html" rel="prev" title="Advanced Model Training with Fully Sharded Data Parallel (FSDP)"/>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
<!-- End Google Tag Manager -->
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Edge
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/edge">
<span class="dropdown-title">About PyTorch Edge</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/executorch">
<span class="dropdown-title">ExecuTorch</span>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-orange-arrow">
                Docs
              </a>
<div class="resources-dropdown-menu">
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
<span class="dropdown-title">torchaudio</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
<span class="dropdown-title">torchtext</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
<span class="dropdown-title">torchvision</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
<span class="dropdown-title">torcharrow</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
<span class="dropdown-title">TorchData</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
<span class="dropdown-title">TorchRec</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
<span class="dropdown-title">TorchServe</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
<span class="dropdown-title">TorchX</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
<span class="dropdown-title">PyTorch on XLA Devices</span>
<p></p>
</a>
</div>
</div></li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
<p>Learn about the PyTorch foundation</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
<span class="dropdown-title">Community</span>
<p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
<span class="dropdown-title">Community Stories</span>
<p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
<p>Find events, webinars, and podcasts</p>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
<span class="dropdown-title">Forums</span>
<p>A place to discuss PyTorch code, issues, install, research</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">GitHub</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  2.2.0+cu121
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="tiatoolbox_tutorial.html">Whole Slide Image Classification Using PyTorch and TIAToolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_to_speech_with_torchaudio.html">Text-to-speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transformer_tutorial.html">Language Modeling with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/translation_transformer.html">Language Translation with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/torchtext_custom_dataset_tutorial.html">Preprocess custom text dataset using Torchtext</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Profiling PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_intro_tutorial.html">Introduction to Holistic Trace Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="scaled_dot_product_attention_tutorial.html#using-sdpa-with-torch-compile">Using SDPA with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="scaled_dot_product_attention_tutorial.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline_tutorial.html">Training Transformer models using Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/ddp_pipeline.html">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_android.html">Image Segmentation DeepLabV3 on Android</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Customize Process Group Backends Using Cpp Extensions</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/intermediate/process_group_cpp_extension_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/process_group_cpp_extension_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg">
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</img></div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="section" id="customize-process-group-backends-using-cpp-extensions">
<h1>Customize Process Group Backends Using Cpp Extensions<a class="headerlink" href="#customize-process-group-backends-using-cpp-extensions" title="Permalink to this heading">¶</a></h1>
<p><strong>Author</strong>: <cite>Howard Huang &lt;https://github.com/H-Huang&gt;</cite>, <a class="reference external" href="https://github.com/ftian1">Feng Tian</a>, <a class="reference external" href="https://mrshenli.github.io/">Shen Li</a>, <a class="reference external" href="https://minsii.github.io/">Min Si</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="../_images/pencil-16.png"><img alt="edit" src="../_images/pencil-16.png" style="width: 16px; height: 16px;"/></a> View and edit this tutorial in <a class="reference external" href="https://github.com/pytorch/tutorials/blob/main/intermediate_source/process_group_cpp_extension_tutorial.rst">github</a>.</p>
</div>
<p>Prerequisites:</p>
<ul class="simple">
<li><p><a class="reference external" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/distributed.html">PyTorch Collective Communication Package</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/cpp_extension.html">PyTorch Cpp Extension</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></p></li>
</ul>
<p>This tutorial demonstrates how to implement a custom <code class="docutils literal notranslate"><span class="pre">Backend</span></code> and plug that into
<a class="reference external" href="https://pytorch.org/docs/stable/distributed.html">PyTorch distributed package</a> using
<a class="reference external" href="https://pytorch.org/docs/stable/cpp_extension.html">cpp extensions</a>. This is helpful when you need a specialized software
stack for your hardware, or when you would like to experiment with new
collective communication algorithms.</p>
<div class="section" id="basics">
<h2>Basics<a class="headerlink" href="#basics" title="Permalink to this heading">¶</a></h2>
<p>PyTorch collective communications power several widely adopted distributed
training features, including
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">DistributedDataParallel</a>,
<a class="reference external" href="https://pytorch.org/docs/stable/distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer">ZeroRedundancyOptimizer</a>,
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/distributed/_fsdp/fully_sharded_data_parallel.py">FullyShardedDataParallel</a>.
In order to make the same collective communication API work with
different communication backends, the distributed package abstracts collective
communication operations into a
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/torch/csrc/distributed/c10d/Backend.hpp">Backend</a>
class. Different backends can
then be implemented as subclasses of <code class="docutils literal notranslate"><span class="pre">Backend</span></code> using preferred
third-party libraries. PyTorch distributed comes with three default backends,
<code class="docutils literal notranslate"><span class="pre">ProcessGroupNCCL</span></code>, <code class="docutils literal notranslate"><span class="pre">ProcessGroupGloo</span></code>, and <code class="docutils literal notranslate"><span class="pre">ProcessGroupMPI</span></code>. However,
beyond these three backends, there are also other communication libraries
(e.g., <a class="reference external" href="https://github.com/openucx/ucc">UCC</a>,
<a class="reference external" href="https://github.com/oneapi-src/oneCCL">OneCCL</a>), different types of hardware
(e.g., <a class="reference external" href="https://cloud.google.com/tpu">TPU</a>,
<a class="reference external" href="https://aws.amazon.com/machine-learning/trainium/">Trainum</a>), and emerging
communication algorithms (e.g.,
<a class="reference external" href="https://www.amazon.science/publications/herring-rethinking-the-parameter-server-at-scale-for-the-cloud">Herring</a>,
<a class="reference external" href="https://cloud.google.com/blog/topics/developers-practitioners/optimize-training-performance-reduction-server-vertex-ai">Reduction Server</a>).
Therefore, the distributed package exposes extension APIs to allow customizing
collective communication backends.</p>
<p>The 4 steps below show how to implement a dummy <code class="docutils literal notranslate"><span class="pre">Backend</span></code> backend
and use that in Python application code. Please note that this tutorial focuses
on demonstrating the extension APIs, instead of developing a functioning
communication backend. Hence, the <code class="docutils literal notranslate"><span class="pre">dummy</span></code> backend just covers a subset of the
APIs (<code class="docutils literal notranslate"><span class="pre">all_reduce</span></code> and <code class="docutils literal notranslate"><span class="pre">all_gather</span></code>), and simply sets the values of tensors
to 0.</p>
</div>
<div class="section" id="step-1-implement-a-subclass-of-backend">
<h2>Step 1: Implement a Subclass of <code class="docutils literal notranslate"><span class="pre">Backend</span></code><a class="headerlink" href="#step-1-implement-a-subclass-of-backend" title="Permalink to this heading">¶</a></h2>
<p>This first step is to implement a <code class="docutils literal notranslate"><span class="pre">Backend</span></code> subclass that overrides
target collective communication APIs and runs the custom communication algorithm.
The extension also needs to implement a <code class="docutils literal notranslate"><span class="pre">Work</span></code> subclass, which
serves as a future of communication results and allows asynchronous execution in
application code. If the extension uses third-party libraries, it can
include the headers and call into the library APIs from the <code class="docutils literal notranslate"><span class="pre">BackendDummy</span></code>
subclass. The two code snippets below present the implementation of <code class="docutils literal notranslate"><span class="pre">dummy.h</span></code> and
<code class="docutils literal notranslate"><span class="pre">dummy.cpp</span></code>. See the <a class="reference external" href="https://github.com/H-Huang/torch_collective_extension">dummy collectives</a>
repository for the full implementation.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// file name: dummy.hpp</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/python.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/distributed/c10d/Backend.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/distributed/c10d/Work.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/distributed/c10d/Store.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/distributed/c10d/Types.hpp&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/csrc/distributed/c10d/Utils.hpp&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;pybind11/chrono.h&gt;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">c10d</span><span class="w"> </span><span class="p">{</span>

<span class="k">class</span><span class="w"> </span><span class="nc">BackendDummy</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Backend</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">public</span><span class="o">:</span>
<span class="w">    </span><span class="n">BackendDummy</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">rank</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>

<span class="w">    </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Work</span><span class="o">&gt;</span><span class="w"> </span><span class="n">allgather</span><span class="p">(</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">outputTensors</span><span class="p">,</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">inputTensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">AllgatherOptions</span><span class="o">&amp;</span><span class="w"> </span><span class="n">opts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AllgatherOptions</span><span class="p">())</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">    </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Work</span><span class="o">&gt;</span><span class="w"> </span><span class="n">allreduce</span><span class="p">(</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">tensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">AllreduceOptions</span><span class="o">&amp;</span><span class="w"> </span><span class="n">opts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">AllreduceOptions</span><span class="p">())</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// The collective communication APIs without a custom implementation</span>
<span class="w">    </span><span class="c1">// will error out if invoked by application code.</span>
<span class="p">};</span>

<span class="k">class</span><span class="w"> </span><span class="nc">WorkDummy</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Work</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">public</span><span class="o">:</span>
<span class="w">    </span><span class="n">WorkDummy</span><span class="p">(</span>
<span class="w">      </span><span class="n">OpType</span><span class="w"> </span><span class="n">opType</span><span class="p">,</span>
<span class="w">      </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">ivalue</span><span class="o">::</span><span class="n">Future</span><span class="o">&gt;</span><span class="w"> </span><span class="n">future</span><span class="p">)</span><span class="w"> </span><span class="c1">// future of the output</span>
<span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">Work</span><span class="p">(</span>
<span class="w">          </span><span class="mi">-1</span><span class="p">,</span><span class="w"> </span><span class="c1">// rank, only used by recvAnySource, irrelevant in this demo</span>
<span class="w">          </span><span class="n">opType</span><span class="p">),</span>
<span class="w">      </span><span class="n">future_</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">future</span><span class="p">))</span><span class="w"> </span><span class="p">{}</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">isCompleted</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="nf">isSuccess</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="nf">wait</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">milliseconds</span><span class="w"> </span><span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kUnsetTimeout</span><span class="p">)</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>
<span class="w">    </span><span class="k">virtual</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">ivalue</span><span class="o">::</span><span class="n">Future</span><span class="o">&gt;</span><span class="w"> </span><span class="n">getFuture</span><span class="p">()</span><span class="w"> </span><span class="k">override</span><span class="p">;</span>

<span class="w">  </span><span class="k">private</span><span class="o">:</span>
<span class="w">    </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">ivalue</span><span class="o">::</span><span class="n">Future</span><span class="o">&gt;</span><span class="w"> </span><span class="n">future_</span><span class="p">;</span>
<span class="p">};</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace c10d</span>
</pre></div>
</div>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// file name: dummy.cpp</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">"dummy.hpp"</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">c10d</span><span class="w"> </span><span class="p">{</span>

<span class="c1">// This is a dummy allgather that sets all output tensors to zero</span>
<span class="c1">// Modify the implementation to conduct real communication asynchronously</span>
<span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Work</span><span class="o">&gt;</span><span class="w"> </span><span class="n">BackendDummy</span><span class="o">::</span><span class="n">allgather</span><span class="p">(</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&gt;&amp;</span><span class="w"> </span><span class="n">outputTensors</span><span class="p">,</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">inputTensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">AllgatherOptions</span><span class="o">&amp;</span><span class="w"> </span><span class="cm">/* unused */</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">outputTensorVec</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputTensors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">outputTensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">outputTensorVec</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">outputTensor</span><span class="p">.</span><span class="n">zero_</span><span class="p">();</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">future</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">ivalue</span><span class="o">::</span><span class="n">Future</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">c10</span><span class="o">::</span><span class="n">ListType</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">ListType</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">TensorType</span><span class="o">::</span><span class="n">get</span><span class="p">())));</span>
<span class="w">    </span><span class="n">future</span><span class="o">-&gt;</span><span class="n">markCompleted</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="p">(</span><span class="n">outputTensors</span><span class="p">));</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">WorkDummy</span><span class="o">&gt;</span><span class="p">(</span><span class="n">OpType</span><span class="o">::</span><span class="n">ALLGATHER</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">future</span><span class="p">));</span>
<span class="p">}</span>

<span class="c1">// This is a dummy allreduce that sets all output tensors to zero</span>
<span class="c1">// Modify the implementation to conduct real communication asynchronously</span>
<span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Work</span><span class="o">&gt;</span><span class="w"> </span><span class="n">BackendDummy</span><span class="o">::</span><span class="n">allreduce</span><span class="p">(</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">at</span><span class="o">::</span><span class="n">Tensor</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">tensors</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">AllreduceOptions</span><span class="o">&amp;</span><span class="w"> </span><span class="n">opts</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">tensor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">tensors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">tensor</span><span class="p">.</span><span class="n">zero_</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">future</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">c10</span><span class="o">::</span><span class="n">ivalue</span><span class="o">::</span><span class="n">Future</span><span class="o">&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">c10</span><span class="o">::</span><span class="n">ListType</span><span class="o">::</span><span class="n">create</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">TensorType</span><span class="o">::</span><span class="n">get</span><span class="p">()));</span>
<span class="w">    </span><span class="n">future</span><span class="o">-&gt;</span><span class="n">markCompleted</span><span class="p">(</span><span class="n">c10</span><span class="o">::</span><span class="n">IValue</span><span class="p">(</span><span class="n">tensors</span><span class="p">));</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">WorkDummy</span><span class="o">&gt;</span><span class="p">(</span><span class="n">OpType</span><span class="o">::</span><span class="n">ALLGATHER</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">future</span><span class="p">));</span>
<span class="p">}</span>
<span class="p">}</span><span class="w"> </span><span class="c1">// namespace c10d</span>
</pre></div>
</div>
</div>
<div class="section" id="step-2-expose-the-extension-python-apis">
<h2>Step 2: Expose The Extension Python APIs<a class="headerlink" href="#step-2-expose-the-extension-python-apis" title="Permalink to this heading">¶</a></h2>
<p>The backend constructors are called
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/v1.9.0/torch/distributed/distributed_c10d.py#L643-L650">from Python side</a>,
so the extension also needs to expose the constructor APIs to Python. This can
be done by adding the following methods. In this example, <code class="docutils literal notranslate"><span class="pre">store</span></code> and
<code class="docutils literal notranslate"><span class="pre">timeout</span></code> are ignored by the <code class="docutils literal notranslate"><span class="pre">BackendDummy</span></code> instantiation method, as
those are not used in this dummy implementation. However, real-world extensions
should consider using the <code class="docutils literal notranslate"><span class="pre">store</span></code> to perform rendezvous and supporting the
<code class="docutils literal notranslate"><span class="pre">timeout</span></code> argument.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// file name: dummy.hpp</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BackendDummy</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">Backend</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="p">...</span>
<span class="w">    </span><span class="o">&lt;</span><span class="n">Step</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">code</span><span class="o">&gt;</span>
<span class="w">    </span><span class="p">...</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Backend</span><span class="o">&gt;</span><span class="w"> </span><span class="n">createBackendDummy</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;::</span><span class="n">c10d</span><span class="o">::</span><span class="n">Store</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">store</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">rank</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">timeout</span><span class="p">);</span>

<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">BackendDummyConstructor</span><span class="p">()</span><span class="w"> </span><span class="n">__attribute__</span><span class="p">((</span><span class="n">constructor</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">py</span><span class="o">::</span><span class="n">object</span><span class="w"> </span><span class="k">module</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">py</span><span class="o">::</span><span class="k">module</span><span class="o">::</span><span class="k">import</span><span class="p">(</span><span class="s">"torch.distributed"</span><span class="p">);</span>
<span class="w">        </span><span class="n">py</span><span class="o">::</span><span class="n">object</span><span class="w"> </span><span class="n">register_backend</span><span class="w"> </span><span class="o">=</span>
<span class="w">            </span><span class="k">module</span><span class="p">.</span><span class="n">attr</span><span class="p">(</span><span class="s">"Backend"</span><span class="p">).</span><span class="n">attr</span><span class="p">(</span><span class="s">"register_backend"</span><span class="p">);</span>
<span class="w">        </span><span class="c1">// torch.distributed.Backend.register_backend will add `dummy` as a</span>
<span class="w">        </span><span class="c1">// new valid backend.</span>
<span class="w">        </span><span class="n">register_backend</span><span class="p">(</span><span class="s">"dummy"</span><span class="p">,</span><span class="w"> </span><span class="n">py</span><span class="o">::</span><span class="n">cpp_function</span><span class="p">(</span><span class="n">createBackendDummy</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// file name: dummy.cpp</span>
<span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;</span><span class="n">Backend</span><span class="o">&gt;</span><span class="w"> </span><span class="n">BackendDummy</span><span class="o">::</span><span class="n">createBackendDummy</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">intrusive_ptr</span><span class="o">&lt;::</span><span class="n">c10d</span><span class="o">::</span><span class="n">Store</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="cm">/* unused */</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">rank</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">size</span><span class="p">,</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="cm">/* unused */</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">c10</span><span class="o">::</span><span class="n">make_intrusive</span><span class="o">&lt;</span><span class="n">BackendDummy</span><span class="o">&gt;</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">PYBIND11_MODULE</span><span class="p">(</span><span class="n">TORCH_EXTENSION_NAME</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">m</span><span class="p">.</span><span class="n">def</span><span class="p">(</span><span class="s">"createBackendDummy"</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">BackendDummy</span><span class="o">::</span><span class="n">createBackendDummy</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="step-3-build-the-custom-extension">
<h2>Step 3: Build The Custom Extension<a class="headerlink" href="#step-3-build-the-custom-extension" title="Permalink to this heading">¶</a></h2>
<p>Now, the extension source code files are ready. We can then use
<a class="reference external" href="https://pytorch.org/docs/stable/cpp_extension.html">cpp extensions</a>
to build it. To do that, create a <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> file that prepares the paths and
commands. Then call <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">develop</span></code> to install the extension.</p>
<p>If the extension depends on third-party libraries, you can also specify
<code class="docutils literal notranslate"><span class="pre">libraries_dirs</span></code> and <code class="docutils literal notranslate"><span class="pre">libraries</span></code> to the cpp extension APIs. See the
<a class="reference external" href="https://github.com/openucx/torch-ucc">torch ucc</a>
project as a real-world example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># file name: setup.py</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">setuptools</span> <span class="kn">import</span> <span class="n">setup</span>
<span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">cpp_extension</span>

<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"src/dummy.cpp"</span><span class="p">]</span>
<span class="n">include_dirs</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span><span class="si">}</span><span class="s2">/include/"</span><span class="p">]</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">cpp_extension</span><span class="o">.</span><span class="n">CUDAExtension</span><span class="p">(</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">"dummy_collectives"</span><span class="p">,</span>
        <span class="n">sources</span> <span class="o">=</span> <span class="n">sources</span><span class="p">,</span>
        <span class="n">include_dirs</span> <span class="o">=</span> <span class="n">include_dirs</span><span class="p">,</span>
    <span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">cpp_extension</span><span class="o">.</span><span class="n">CppExtension</span><span class="p">(</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">"dummy_collectives"</span><span class="p">,</span>
        <span class="n">sources</span> <span class="o">=</span> <span class="n">sources</span><span class="p">,</span>
        <span class="n">include_dirs</span> <span class="o">=</span> <span class="n">include_dirs</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">setup</span><span class="p">(</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">"Dummy-Collectives"</span><span class="p">,</span>
    <span class="n">version</span> <span class="o">=</span> <span class="s2">"0.0.1"</span><span class="p">,</span>
    <span class="n">ext_modules</span> <span class="o">=</span> <span class="p">[</span><span class="n">module</span><span class="p">],</span>
    <span class="n">cmdclass</span><span class="o">=</span><span class="p">{</span><span class="s1">'build_ext'</span><span class="p">:</span> <span class="n">cpp_extension</span><span class="o">.</span><span class="n">BuildExtension</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="step-4-use-the-extension-in-application">
<h2>Step 4: Use The Extension in Application<a class="headerlink" href="#step-4-use-the-extension-in-application" title="Permalink to this heading">¶</a></h2>
<p>After installation, you can conveniently use the <code class="docutils literal notranslate"><span class="pre">dummy</span></code> backend when calling
<a class="reference external" href="https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group">init_process_group</a>
as if it is an builtin backend.</p>
<p>We can specify dispatching based on backend by changing the <code class="docutils literal notranslate"><span class="pre">backend</span></code> argument of <code class="docutils literal notranslate"><span class="pre">init_process_group</span></code>. We
can dispatch collective with CPU tensor to <code class="docutils literal notranslate"><span class="pre">gloo</span></code> backend and dispatch collective with CUDA tensor to <code class="docutils literal notranslate"><span class="pre">dummy</span></code> backend by
specifying <code class="docutils literal notranslate"><span class="pre">cpu:gloo,cuda:dummy</span></code> as the backend argument.</p>
<p>To send all tensors to <code class="docutils literal notranslate"><span class="pre">dummy</span></code> backend, we can simply specify <code class="docutils literal notranslate"><span class="pre">dummy</span></code> as the backend argument.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># importing dummy_collectives makes torch.distributed recognize `dummy`</span>
<span class="c1"># as a valid backend.</span>
<span class="kn">import</span> <span class="nn">dummy_collectives</span>

<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'MASTER_ADDR'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'localhost'</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">'MASTER_PORT'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'29500'</span>

<span class="c1"># Alternatively:</span>
<span class="c1"># dist.init_process_group("dummy", rank=0, world_size=1)</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">"cpu:gloo,cuda:dummy"</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># this goes through gloo</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cpu allreduce: </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># this goes through dummy</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"cuda allreduce: </span><span class="si">{</span><span class="n">y</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"got RuntimeError when calling broadcast"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="rpc_tutorial.html" rel="next" title="Getting Started with Distributed RPC Framework">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="FSDP_adavnced_tutorial.html" rel="prev" title="Advanced Model Training with Fully Sharded Data Parallel (FSDP)"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="rating-hr hr-top"/>
<div class="rating-container">
<div class="rating-prompt">Rate this Tutorial</div>
<div class="stars-outer">
<i class="far fa-star" data-behavior="tutorial-rating" data-count="1" title="1 Star"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="2" title="2 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="3" title="3 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="4" title="4 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="5" title="5 Stars"></i>
</div>
</div>
<hr class="rating-hr hr-bottom">
<div role="contentinfo">
<p>
        © Copyright 2024, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</hr></footer>
</div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Customize Process Group Backends Using Cpp Extensions</a><ul>
<li><a class="reference internal" href="#basics">Basics</a></li>
<li><a class="reference internal" href="#step-1-implement-a-subclass-of-backend">Step 1: Implement a Subclass of <code class="docutils literal notranslate"><span class="pre">Backend</span></code></a></li>
<li><a class="reference internal" href="#step-2-expose-the-extension-python-apis">Step 2: Expose The Extension Python APIs</a></li>
<li><a class="reference internal" href="#step-3-build-the-custom-extension">Step 3: Build The Custom Extension</a></li>
<li><a class="reference internal" href="#step-4-use-the-extension-in-application">Step 4: Use The Extension in Application</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/katex.min.js"></script>
<script src="../_static/auto-render.min.js"></script>
<script src="../_static/katex_autorenderer.js"></script>
<script src="../_static/design-tabs.js"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });

    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1">
</img></noscript>
<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Mobile'];
</script>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1">
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">Stay up to date</li>
<li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">PyTorch Podcasts</li>
<li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
<li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
<li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
</ul>
</div>
</div>
<div class="privacy-policy">
<ul>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
<li class="privacy-policy-links">|</li>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
</ul>
</div>
<div class="copyright">
<p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg"/>
</div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li class="resources-mobile-menu-title">
            Docs
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
</li>
<li>
<a href="https://pytorch.org/text/stable/index.html">torchtext</a>
</li>
<li>
<a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
</li>
<li>
<a href="https://pytorch.org/torcharrow">torcharrow</a>
</li>
<li>
<a href="https://pytorch.org/data">TorchData</a>
</li>
<li>
<a href="https://pytorch.org/torchrec">TorchRec</a>
</li>
<li>
<a href="https://pytorch.org/serve/">TorchServe</a>
</li>
<li>
<a href="https://pytorch.org/torchx/">TorchX</a>
</li>
<li>
<a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
            Resources
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/features">About</a>
</li>
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/#community-module">Community</a>
</li>
<li>
<a href="https://pytorch.org/community-stories">Community Stories</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/hub">Models (Beta)</a>
</li>
</ul>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</img></body>
</html>