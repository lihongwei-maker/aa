
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Extending the ONNX Registry — PyTorch Tutorials 2.2.0+cu121 documentation</title>
<link href="../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/katex-math.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/custom2.css" rel="stylesheet" type="text/css"/>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
<!-- End Google Tag Manager -->
<script src="../../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Edge
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/edge">
<span class="dropdown-title">About PyTorch Edge</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/executorch">
<span class="dropdown-title">ExecuTorch</span>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-orange-arrow">
                Docs
              </a>
<div class="resources-dropdown-menu">
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
<span class="dropdown-title">torchaudio</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
<span class="dropdown-title">torchtext</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
<span class="dropdown-title">torchvision</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
<span class="dropdown-title">torcharrow</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
<span class="dropdown-title">TorchData</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
<span class="dropdown-title">TorchRec</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
<span class="dropdown-title">TorchServe</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
<span class="dropdown-title">TorchX</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
<span class="dropdown-title">PyTorch on XLA Devices</span>
<p></p>
</a>
</div>
</div></li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
<p>Learn about the PyTorch foundation</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
<span class="dropdown-title">Community</span>
<p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
<span class="dropdown-title">Community Stories</span>
<p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
<p>Find events, webinars, and podcasts</p>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
<span class="dropdown-title">Forums</span>
<p>A place to discuss PyTorch code, issues, install, research</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">GitHub</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  2.2.0+cu121
                </div>
<div role="search">
<form action="../../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tiatoolbox_tutorial.html">Whole Slide Image Classification Using PyTorch and TIAToolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/text_to_speech_with_torchaudio.html">Text-to-speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../transformer_tutorial.html">Language Modeling with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../translation_transformer.html">Language Translation with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torchtext_custom_dataset_tutorial.html">Preprocess custom text dataset using Torchtext</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_onnx.html">Introduction to ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/reinforcement_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro_onnx.html">Introduction to ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Profiling PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hta_intro_tutorial.html">Introduction to Holistic Trace Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-torch-compile">Using SDPA with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/pipeline_tutorial.html">Training Transformer models using Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/ddp_pipeline.html">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deeplabv3_on_android.html">Image Segmentation DeepLabV3 on Android</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intermediate/torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Extending the ONNX Registry</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../../_sources/beginner/onnx/onnx_registry_tutorial.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/onnx/onnx_registry_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-beginner-onnx-onnx-registry-tutorial-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<p class="sphx-glr-example-title" id="sphx-glr-beginner-onnx-onnx-registry-tutorial-py"><a class="reference external" href="intro_onnx.html">Introduction to ONNX</a> ||
<a class="reference external" href="export_simple_model_to_onnx_tutorial.html">Exporting a PyTorch model to ONNX</a> ||
<strong>Extending the ONNX Registry</strong></p>
<div class="section" id="extending-the-onnx-registry">
<h1>Extending the ONNX Registry<a class="headerlink" href="#extending-the-onnx-registry" title="Permalink to this heading">¶</a></h1>
<p><strong>Authors:</strong> Ti-Tai Wang (<a class="reference external" href="mailto:titaiwang%40microsoft.com">titaiwang<span>@</span>microsoft<span>.</span>com</a>)</p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<p>This tutorial is an introduction to ONNX registry, which empowers users to implement new ONNX operators
or even replace existing operators with a new implementation.</p>
<p>During the model export to ONNX, the PyTorch model is lowered to an intermediate
representation composed of <a class="reference external" href="https://pytorch.org/docs/stable/torch.compiler_ir.html">ATen operators</a>.
While ATen operators are maintained by PyTorch core team, it is the responsibility of the ONNX exporter team
to independently implement each of these operators to ONNX through <a class="reference external" href="https://onnxscript.ai/">ONNX Script</a>.
The users can also replace the behavior implemented by the ONNX exporter team with their own implementation
to fix bugs or improve performance for a specific ONNX runtime.</p>
<p>The ONNX Registry manages the mapping between PyTorch operators and the ONNX operators counterparts and provides
APIs to extend the registry.</p>
<p>In this tutorial, we will cover three scenarios that require extending the ONNX registry with custom operators:</p>
<ul class="simple">
<li><p>Unsupported ATen operators</p></li>
<li><p>Custom operators with existing ONNX Runtime support</p></li>
<li><p>Custom operators without ONNX Runtime support</p></li>
</ul>
</div>
<div class="section" id="unsupported-aten-operators">
<h2>Unsupported ATen operators<a class="headerlink" href="#unsupported-aten-operators" title="Permalink to this heading">¶</a></h2>
<p>Although the ONNX exporter team does their best efforts to support all ATen operators, some of them
might not be supported yet. In this section, we will demonstrate how you can add
unsupported ATen operators to the ONNX Registry.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The steps to implement unsupported ATen operators are the same to replace the implementation of an existing
ATen operator with a custom implementation.
Because we don’t actually have an unsupported ATen operator to use in this tutorial, we are going to leverage
this and replace the implementation of <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code> with a custom implementation the same way we would
if the operator was not present in the ONNX Registry.</p>
</div>
<p>When a model cannot be exported to ONNX due to an unsupported operator, the ONNX exporter will show an error message
similar to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">RuntimeErrorWithDiagnostic</span><span class="p">:</span> <span class="n">Unsupported</span> <span class="n">FX</span> <span class="n">nodes</span><span class="p">:</span> <span class="p">{</span><span class="s1">'call_function'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'aten.add.Tensor'</span><span class="p">]}</span><span class="o">.</span>
</pre></div>
</div>
<p>The error message indicates that the fully qualified name of unsupported ATen operator is <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code>.
The fully qualified name of an operator is composed of the namespace, operator name, and overload following
the format <code class="docutils literal notranslate"><span class="pre">namespace::operator_name.overload</span></code>.</p>
<p>To add support for an unsupported ATen operator or to replace the implementation for an existing one, we need:</p>
<ul class="simple">
<li><p>The fully qualified name of the ATen operator (e.g. <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code>).
This information is always present in the error message as show above.</p></li>
<li><p>The implementation of the operator using <a class="reference external" href="https://github.com/microsoft/onnxscript">ONNX Script</a>.
ONNX Script is a prerequisite for this tutorial. Please make sure you have read the
<a class="reference external" href="https://github.com/microsoft/onnxscript/blob/main/docs/tutorial/index.md">ONNX Script tutorial</a>
before proceeding.</p></li>
</ul>
<p>Because <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code> is already supported by the ONNX Registry, we will demonstrate how to replace it with a
custom implementation, but keep in mind that the same steps apply to support new unsupported ATen operators.</p>
<p>This is possible because the <code class="xref py py-class docutils literal notranslate"><span class="pre">OnnxRegistry</span></code> allows users to override an operator registration.
We will override the registration of <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code> with our custom implementation and verify it exists.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span>
<span class="kn">import</span> <span class="nn">onnxscript</span>
<span class="kn">from</span> <span class="nn">onnxscript</span> <span class="kn">import</span> <span class="n">opset18</span>  <span class="c1"># opset 18 is the latest (and only) supported version for now</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>  <span class="c1"># generates a aten::add.Tensor node</span>

<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_y</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">aten_add_model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Model</span></a><span class="p">()</span>


<span class="c1"># Now we create a ONNX Script function that implements ``aten::add.Tensor``.</span>
<span class="c1"># The function name (e.g. ``custom_aten_add``) is displayed in the ONNX graph, so we recommend to use intuitive names.</span>
<span class="n">custom_aten</span> <span class="o">=</span> <span class="n">onnxscript</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">Opset</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="s2">"custom.aten"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># NOTE: The function signature must match the signature of the unsupported ATen operator.</span>
<span class="c1"># https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml</span>
<span class="c1"># NOTE: All attributes must be annotated with type hints.</span>
<span class="nd">@onnxscript</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">custom_aten</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">custom_aten_add</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">opset18</span><span class="o">.</span><span class="n">CastLike</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>
    <span class="n">input_y</span> <span class="o">=</span> <span class="n">opset18</span><span class="o">.</span><span class="n">Mul</span><span class="p">(</span><span class="n">input_y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">opset18</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_y</span><span class="p">)</span>


<span class="c1"># Now we have everything we need to support unsupported ATen operators.</span>
<span class="c1"># Let's register the ``custom_aten_add`` function to ONNX registry, and export the model to ONNX again.</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">OnnxRegistry</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry.register_op" title="torch.onnx.OnnxRegistry.register_op"><span class="n">onnx_registry</span><span class="o">.</span><span class="n">register_op</span></a><span class="p">(</span>
    <span class="n">namespace</span><span class="o">=</span><span class="s2">"aten"</span><span class="p">,</span> <span class="n">op_name</span><span class="o">=</span><span class="s2">"add"</span><span class="p">,</span> <span class="n">overload</span><span class="o">=</span><span class="s2">"Tensor"</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">custom_aten_add</span>
    <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"aten::add.Tensor is supported by ONNX registry: </span><span class="se">\</span>
<span class="s2">      </span><span class="si">{</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry.is_registered_op" title="torch.onnx.OnnxRegistry.is_registered_op"><span class="n">onnx_registry</span><span class="o">.</span><span class="n">is_registered_op</span></a><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s1">'aten'</span><span class="p">,</span><span class="w"> </span><span class="n">op_name</span><span class="o">=</span><span class="s1">'add'</span><span class="p">,</span><span class="w"> </span><span class="n">overload</span><span class="o">=</span><span class="s1">'Tensor'</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
      <span class="p">)</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ExportOptions</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram" title="torch.onnx.ONNXProgram"><span class="n">onnx_program</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.dynamo_export" title="torch.onnx.dynamo_export"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span></a><span class="p">(</span>
    <span class="n">aten_add_model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a>
    <span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning:

torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.

aten::add.Tensor is supported by ONNX registry:       True
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning:

torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
</pre></div>
</div>
<p>Now let’s inspect the model and verify the model has a <code class="docutils literal notranslate"><span class="pre">custom_aten_add</span></code> instead of <code class="docutils literal notranslate"><span class="pre">aten::add.Tensor</span></code>.
The graph has one graph node for <code class="docutils literal notranslate"><span class="pre">custom_aten_add</span></code>, and inside of it there are four function nodes, one for each
operator, and one for constant attribute.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># graph node domain is the custom domain we registered</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"custom.aten"</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<span class="c1"># graph node name is the function name</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"custom_aten_add"</span>
<span class="c1"># function node domain is empty because we use standard ONNX operators</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">""</span>
<span class="c1"># function node name is the standard ONNX operator name</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"Add"</span>
</pre></div>
</div>
<p>This is how <code class="docutils literal notranslate"><span class="pre">custom_aten_add_model</span></code> looks in the ONNX graph using Netron:</p>
<a class="reference internal image-reference" href="../../_images/custom_aten_add_model.png"><img alt="../../_images/custom_aten_add_model.png" class="align-center" src="../../_images/custom_aten_add_model.png" style="width: 70%;"/></a>
<p>Inside the <code class="docutils literal notranslate"><span class="pre">custom_aten_add</span></code> function, we can see the three ONNX nodes we
used in the function (<code class="docutils literal notranslate"><span class="pre">CastLike</span></code>, <code class="docutils literal notranslate"><span class="pre">Add</span></code>, and <code class="docutils literal notranslate"><span class="pre">Mul</span></code>), and one <code class="docutils literal notranslate"><span class="pre">Constant</span></code> attribute:</p>
<a class="reference internal image-reference" href="../../_images/custom_aten_add_function.png"><img alt="../../_images/custom_aten_add_function.png" class="align-center" src="../../_images/custom_aten_add_function.png" style="width: 70%;"/></a>
<p>This was all that we needed to register the new ATen operator into the ONNX Registry.
As an additional step, we can use ONNX Runtime to run the model, and compare the results with PyTorch.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use ONNX Runtime to run the model, and compare the results with PyTorch</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.save" title="torch.onnx.ONNXProgram.save"><span class="n">onnx_program</span><span class="o">.</span><span class="n">save</span></a><span class="p">(</span><span class="s2">"./custom_add_model.onnx"</span><span class="p">)</span>
<span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
    <span class="s2">"./custom_add_model.onnx"</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">'CPUExecutionProvider'</span><span class="p">]</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">to_numpy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">onnx_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_inputs_to_onnx</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_y</span></a><span class="p">)</span>
<span class="n">onnxruntime_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(),</span> <span class="n">onnx_input</span><span class="p">)}</span>
<span class="n">onnxruntime_outputs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">onnxruntime_input</span><span class="p">)</span>

<span class="n">torch_outputs</span> <span class="o">=</span> <span class="n">aten_add_model</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_add_y</span></a><span class="p">)</span>
<span class="n">torch_outputs</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_outputs_to_onnx</span></a><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnxruntime_outputs</span><span class="p">)</span>
<span class="k">for</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <span class="n">onnxruntime_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">,</span> <span class="n">onnxruntime_outputs</span><span class="p">):</span>
    <a class="sphx-glr-backref-module-torch-testing sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/testing.html#torch.testing.assert_close" title="torch.testing.assert_close"><span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="n">onnxruntime_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-operators-with-existing-onnx-runtime-support">
<h2>Custom operators with existing ONNX Runtime support<a class="headerlink" href="#custom-operators-with-existing-onnx-runtime-support" title="Permalink to this heading">¶</a></h2>
<p>In this case, the user creates a model with standard PyTorch operators, but the ONNX runtime
(e.g. Microsoft’s ONNX Runtime) can provide a custom implementation for that kernel, effectively replacing the
existing implementation in the ONNX Registry. Another use case is when the user wants to use a custom implementation
of an existing ONNX operator to fix a bug or improve performance of a specific operator.
To achieve this, we only need to register the new implementation with the existing ATen fully qualified name.</p>
<p>In the following example, we use the <code class="docutils literal notranslate"><span class="pre">com.microsoft.Gelu</span></code> from ONNX Runtime,
which is not the same <code class="docutils literal notranslate"><span class="pre">Gelu</span></code> from ONNX spec. Thus, we register the Gelu with
the namespace <code class="docutils literal notranslate"><span class="pre">com.microsoft</span></code> and operator name <code class="docutils literal notranslate"><span class="pre">Gelu</span></code>.</p>
<p>Before we begin, let’s check whether <code class="docutils literal notranslate"><span class="pre">aten::gelu.default</span></code> is really supported by the ONNX registry.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">OnnxRegistry</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"aten::gelu.default is supported by ONNX registry: </span><span class="se">\</span>
<span class="s2">    </span><span class="si">{</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry.is_registered_op" title="torch.onnx.OnnxRegistry.is_registered_op"><span class="n">onnx_registry</span><span class="o">.</span><span class="n">is_registered_op</span></a><span class="p">(</span><span class="n">namespace</span><span class="o">=</span><span class="s1">'aten'</span><span class="p">,</span><span class="w"> </span><span class="n">op_name</span><span class="o">=</span><span class="s1">'gelu'</span><span class="p">,</span><span class="w"> </span><span class="n">overload</span><span class="o">=</span><span class="s1">'default'</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning:

torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.

aten::gelu.default is supported by ONNX registry:     True
</pre></div>
</div>
<p>In our example, <code class="docutils literal notranslate"><span class="pre">aten::gelu.default</span></code> operator is supported by the ONNX registry,
so <code class="xref py py-meth docutils literal notranslate"><span class="pre">onnx_registry.is_registered_op()</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CustomGelu</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>

<span class="c1"># com.microsoft is an official ONNX Runtime namspace</span>
<span class="n">custom_ort</span> <span class="o">=</span> <span class="n">onnxscript</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">Opset</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="s2">"com.microsoft"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># NOTE: The function signature must match the signature of the unsupported ATen operator.</span>
<span class="c1"># https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml</span>
<span class="c1"># NOTE: All attributes must be annotated with type hints.</span>
<span class="nd">@onnxscript</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">custom_ort</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">custom_aten_gelu</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">approximate</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"none"</span><span class="p">):</span>
    <span class="c1"># We know com.microsoft::Gelu is supported by ONNX Runtime</span>
    <span class="c1"># It's only not supported by ONNX</span>
    <span class="k">return</span> <span class="n">custom_ort</span><span class="o">.</span><span class="n">Gelu</span><span class="p">(</span><span class="n">input_x</span><span class="p">)</span>


<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">OnnxRegistry</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry.register_op" title="torch.onnx.OnnxRegistry.register_op"><span class="n">onnx_registry</span><span class="o">.</span><span class="n">register_op</span></a><span class="p">(</span>
    <span class="n">namespace</span><span class="o">=</span><span class="s2">"aten"</span><span class="p">,</span> <span class="n">op_name</span><span class="o">=</span><span class="s2">"gelu"</span><span class="p">,</span> <span class="n">overload</span><span class="o">=</span><span class="s2">"default"</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">custom_aten_gelu</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ExportOptions</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="p">)</span>

<span class="n">aten_gelu_model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">CustomGelu</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_gelu_x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram" title="torch.onnx.ONNXProgram"><span class="n">onnx_program</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.dynamo_export" title="torch.onnx.dynamo_export"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span></a><span class="p">(</span>
    <span class="n">aten_gelu_model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_gelu_x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a>
    <span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>'Gelu' is not a known op in 'com.microsoft'
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning:

torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
</pre></div>
</div>
<p>Let’s inspect the model and verify the model uses <code class="xref py py-func docutils literal notranslate"><span class="pre">custom_aten_gelu()</span></code> instead of
<code class="xref py py-class docutils literal notranslate"><span class="pre">aten::gelu</span></code>. Note the graph has one graph nodes for
<code class="docutils literal notranslate"><span class="pre">custom_aten_gelu</span></code>, and inside <code class="docutils literal notranslate"><span class="pre">custom_aten_gelu</span></code>, there is a function
node for <code class="docutils literal notranslate"><span class="pre">Gelu</span></code> with namespace <code class="docutils literal notranslate"><span class="pre">com.microsoft</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># graph node domain is the custom domain we registered</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"com.microsoft"</span>
<span class="c1"># graph node name is the function name</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"custom_aten_gelu"</span>
<span class="c1"># function node domain is the custom domain we registered</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"com.microsoft"</span>
<span class="c1"># function node name is the node name used in the function</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"Gelu"</span>
</pre></div>
</div>
<p>The following diagram shows <code class="docutils literal notranslate"><span class="pre">custom_aten_gelu_model</span></code> ONNX graph using Netron:</p>
<a class="reference internal image-reference" href="../../_images/custom_aten_gelu_model.png"><img alt="../../_images/custom_aten_gelu_model.png" class="align-center" src="../../_images/custom_aten_gelu_model.png" style="width: 70%;"/></a>
<p>Inside the <code class="docutils literal notranslate"><span class="pre">custom_aten_gelu</span></code> function, we can see the <code class="docutils literal notranslate"><span class="pre">Gelu</span></code> node from module
<code class="docutils literal notranslate"><span class="pre">com.microsoft</span></code> used in the function:</p>
<img alt="../../_images/custom_aten_gelu_function.png" src="../../_images/custom_aten_gelu_function.png"/>
<p>That is all we need to do. As an additional step, we can use ONNX Runtime to run the model,
and compare the results with PyTorch.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.save" title="torch.onnx.ONNXProgram.save"><span class="n">onnx_program</span><span class="o">.</span><span class="n">save</span></a><span class="p">(</span><span class="s2">"./custom_gelu_model.onnx"</span><span class="p">)</span>
<span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
    <span class="s2">"./custom_gelu_model.onnx"</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">'CPUExecutionProvider'</span><span class="p">]</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">to_numpy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">onnx_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_inputs_to_onnx</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_gelu_x</span></a><span class="p">)</span>
<span class="n">onnxruntime_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(),</span> <span class="n">onnx_input</span><span class="p">)}</span>
<span class="n">onnxruntime_outputs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">onnxruntime_input</span><span class="p">)</span>

<span class="n">torch_outputs</span> <span class="o">=</span> <span class="n">aten_gelu_model</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_gelu_x</span></a><span class="p">)</span>
<span class="n">torch_outputs</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_outputs_to_onnx</span></a><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnxruntime_outputs</span><span class="p">)</span>
<span class="k">for</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <span class="n">onnxruntime_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">,</span> <span class="n">onnxruntime_outputs</span><span class="p">):</span>
    <a class="sphx-glr-backref-module-torch-testing sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/testing.html#torch.testing.assert_close" title="torch.testing.assert_close"><span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="n">onnxruntime_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-operators-without-onnx-runtime-support">
<h2>Custom operators without ONNX Runtime support<a class="headerlink" href="#custom-operators-without-onnx-runtime-support" title="Permalink to this heading">¶</a></h2>
<p>In this case, the operator is not supported by any ONNX runtime, but we
would like to use it as custom operator in ONNX graph. Therefore, we need to implement
the operator in three places:</p>
<ol class="arabic simple">
<li><p>PyTorch FX graph</p></li>
<li><p>ONNX Registry</p></li>
<li><p>ONNX Runtime</p></li>
</ol>
<p>In the following example, we would like to use a custom operator
that takes one tensor input, and returns one output. The operator adds
the input to itself, and returns the rounded result.</p>
<div class="section" id="custom-ops-registration-in-pytorch-fx-graph-beta">
<h3>Custom Ops Registration in PyTorch FX Graph (Beta)<a class="headerlink" href="#custom-ops-registration-in-pytorch-fx-graph-beta" title="Permalink to this heading">¶</a></h3>
<p>Firstly, we need to implement the operator in PyTorch FX graph.
This can be done by using <code class="docutils literal notranslate"><span class="pre">torch._custom_op</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: This is a beta feature in PyTorch, and is subject to change.</span>
<span class="kn">from</span> <span class="nn">torch._custom_op</span> <span class="kn">import</span> <span class="n">impl</span> <span class="k">as</span> <span class="n">custom_op</span>

<span class="nd">@custom_op</span><span class="o">.</span><span class="n">custom_op</span><span class="p">(</span><span class="s2">"mylibrary::addandround_op"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">addandround_op</span><span class="p">(</span><span class="n">tensor_x</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">)</span> <span class="o">-&gt;</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">:</span>
    <span class="o">...</span>

<span class="nd">@addandround_op</span><span class="o">.</span><span class="n">impl_abstract</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">addandround_op_impl_abstract</span><span class="p">(</span><span class="n">tensor_x</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.empty_like.html#torch.empty_like" title="torch.empty_like"><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span></a><span class="p">(</span><span class="n">tensor_x</span><span class="p">)</span>

<span class="nd">@addandround_op</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">addandround_op_impl</span><span class="p">(</span><span class="n">tensor_x</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.round.html#torch.round" title="torch.round"><span class="n">torch</span><span class="o">.</span><span class="n">round</span></a><span class="p">(</span><span class="n">tensor_x</span> <span class="o">+</span> <span class="n">tensor_x</span><span class="p">)</span>  <span class="c1"># add x to itself, and round the result</span>

<span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">allow_in_graph</span><span class="p">(</span><span class="n">addandround_op</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">CustomFoo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor_x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">addandround_op</span><span class="p">(</span><span class="n">tensor_x</span><span class="p">)</span>

<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_addandround_x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">custom_addandround_model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">CustomFoo</span></a><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-ops-registration-in-onnx-registry">
<h3>Custom Ops Registration in ONNX Registry<a class="headerlink" href="#custom-ops-registration-in-onnx-registry" title="Permalink to this heading">¶</a></h3>
<p>For the step 2 and 3, we need to implement the operator in ONNX registry.
In this example, we will implement the operator in ONNX registry
with the namespace <code class="docutils literal notranslate"><span class="pre">test.customop</span></code> and operator name <code class="docutils literal notranslate"><span class="pre">CustomOpOne</span></code>,
and <code class="docutils literal notranslate"><span class="pre">CustomOpTwo</span></code>. These two ops are registered and built in
<a class="reference external" href="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/test/testdata/custom_op_library/cpu/cpu_ops.cc">cpu_ops.cc</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">custom_opset</span> <span class="o">=</span> <span class="n">onnxscript</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">Opset</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="s2">"test.customop"</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># NOTE: The function signature must match the signature of the unsupported ATen operator.</span>
<span class="c1"># https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml</span>
<span class="c1"># NOTE: All attributes must be annotated with type hints.</span>
<span class="nd">@onnxscript</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">custom_opset</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">custom_addandround</span><span class="p">(</span><span class="n">input_x</span><span class="p">):</span>
    <span class="c1"># The same as opset18.Add(x, x)</span>
    <span class="n">add_x</span> <span class="o">=</span> <span class="n">custom_opset</span><span class="o">.</span><span class="n">CustomOpOne</span><span class="p">(</span><span class="n">input_x</span><span class="p">,</span> <span class="n">input_x</span><span class="p">)</span>
    <span class="c1"># The same as opset18.Round(x, x)</span>
    <span class="n">round_x</span> <span class="o">=</span> <span class="n">custom_opset</span><span class="o">.</span><span class="n">CustomOpTwo</span><span class="p">(</span><span class="n">add_x</span><span class="p">)</span>
    <span class="c1"># Cast to FLOAT to match the ONNX type</span>
    <span class="k">return</span> <span class="n">opset18</span><span class="o">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">round_x</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">OnnxRegistry</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry.register_op" title="torch.onnx.OnnxRegistry.register_op"><span class="n">onnx_registry</span><span class="o">.</span><span class="n">register_op</span></a><span class="p">(</span>
    <span class="n">namespace</span><span class="o">=</span><span class="s2">"mylibrary"</span><span class="p">,</span> <span class="n">op_name</span><span class="o">=</span><span class="s2">"addandround_op"</span><span class="p">,</span> <span class="n">overload</span><span class="o">=</span><span class="s2">"default"</span><span class="p">,</span> <span class="n">function</span><span class="o">=</span><span class="n">custom_addandround</span>
    <span class="p">)</span>

<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ExportOptions</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.OnnxRegistry" title="torch.onnx.OnnxRegistry"><span class="n">onnx_registry</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram" title="torch.onnx.ONNXProgram"><span class="n">onnx_program</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.dynamo_export" title="torch.onnx.dynamo_export"><span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">dynamo_export</span></a><span class="p">(</span>
    <span class="n">custom_addandround_model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_addandround_x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ExportOptions" title="torch.onnx.ExportOptions"><span class="n">export_options</span></a>
    <span class="p">)</span>
<a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.save" title="torch.onnx.ONNXProgram.save"><span class="n">onnx_program</span><span class="o">.</span><span class="n">save</span></a><span class="p">(</span><span class="s2">"./custom_addandround_model.onnx"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>'CustomOpOne' is not a known op in 'test.customop'
'CustomOpTwo' is not a known op in 'test.customop'
/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning:

torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">onnx_program</span></code> exposes the exported model as protobuf through <code class="docutils literal notranslate"><span class="pre">onnx_program.model_proto</span></code>.
The graph has one graph nodes for <code class="docutils literal notranslate"><span class="pre">custom_addandround</span></code>, and inside <code class="docutils literal notranslate"><span class="pre">custom_addandround</span></code>,
there are two function nodes, one for each operator.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"test.customop"</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"custom_addandround"</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"test.customop"</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"CustomOpOne"</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">"test.customop"</span>
<span class="k">assert</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto" title="torch.onnx.ONNXProgram.model_proto"><span class="n">onnx_program</span><span class="o">.</span><span class="n">model_proto</span><span class="o">.</span><span class="n">functions</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">node</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">"CustomOpTwo"</span>
</pre></div>
</div>
<p>This is how <code class="docutils literal notranslate"><span class="pre">custom_addandround_model</span></code> ONNX graph looks using Netron:</p>
<a class="reference internal image-reference" href="../../_images/custom_addandround_model.png"><img alt="../../_images/custom_addandround_model.png" class="align-center" src="../../_images/custom_addandround_model.png" style="width: 70%;"/></a>
<p>Inside the <code class="docutils literal notranslate"><span class="pre">custom_addandround</span></code> function, we can see the two custom operators we
used in the function (<code class="docutils literal notranslate"><span class="pre">CustomOpOne</span></code>, and <code class="docutils literal notranslate"><span class="pre">CustomOpTwo</span></code>), and they are from module
<code class="docutils literal notranslate"><span class="pre">test.customop</span></code>:</p>
<img alt="../../_images/custom_addandround_function.png" src="../../_images/custom_addandround_function.png"/>
</div>
<div class="section" id="custom-ops-registration-in-onnx-runtime">
<h3>Custom Ops Registration in ONNX Runtime<a class="headerlink" href="#custom-ops-registration-in-onnx-runtime" title="Permalink to this heading">¶</a></h3>
<p>To link your custom op library to ONNX Runtime, you need to
compile your C++ code into a shared library and link it to ONNX Runtime.
Follow the instructions below:</p>
<ol class="arabic simple">
<li><p>Implement your custom op in C++ by following
<a class="reference external" href="`https://github.com/microsoft/onnxruntime/blob/gh-pages/docs/reference/operators/add-custom-op.md">ONNX Runtime instructions</a>.</p></li>
<li><p>Download ONNX Runtime source distribution from
<a class="reference external" href="https://github.com/microsoft/onnxruntime/releases">ONNX Runtime releases</a>.</p></li>
<li><p>Compile and link your custom op library to ONNX Runtime, for example:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>gcc<span class="w"> </span>-shared<span class="w"> </span>-o<span class="w"> </span>libcustom_op_library.so<span class="w"> </span>custom_op_library.cc<span class="w"> </span>-L<span class="w"> </span>/path/to/downloaded/ort/lib/<span class="w"> </span>-lonnxruntime<span class="w"> </span>-fPIC
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Run the model with ONNX Runtime Python API and compare the results with PyTorch.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ort_session_options</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">SessionOptions</span><span class="p">()</span>

<span class="c1"># NOTE: Link the custom op library to ONNX Runtime and replace the path</span>
<span class="c1"># with the path to your custom op library</span>
<span class="n">ort_session_options</span><span class="o">.</span><span class="n">register_custom_ops_library</span><span class="p">(</span>
    <span class="s2">"/path/to/libcustom_op_library.so"</span>
<span class="p">)</span>
<span class="n">ort_session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span>
    <span class="s2">"./custom_addandround_model.onnx"</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">'CPUExecutionProvider'</span><span class="p">],</span> <span class="n">sess_options</span><span class="o">=</span><span class="n">ort_session_options</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">to_numpy</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">else</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">onnx_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_inputs_to_onnx</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_addandround_x</span></a><span class="p">)</span>
<span class="n">onnxruntime_input</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">to_numpy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ort_session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(),</span> <span class="n">onnx_input</span><span class="p">)}</span>
<span class="n">onnxruntime_outputs</span> <span class="o">=</span> <span class="n">ort_session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">onnxruntime_input</span><span class="p">)</span>

<span class="n">torch_outputs</span> <span class="o">=</span> <span class="n">custom_addandround_model</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">input_addandround_x</span></a><span class="p">)</span>
<span class="n">torch_outputs</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-onnx sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx" title="torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx"><span class="n">onnx_program</span><span class="o">.</span><span class="n">adapt_torch_outputs_to_onnx</span></a><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">onnxruntime_outputs</span><span class="p">)</span>
<span class="k">for</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <span class="n">onnxruntime_output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">torch_outputs</span><span class="p">,</span> <span class="n">onnxruntime_outputs</span><span class="p">):</span>
    <a class="sphx-glr-backref-module-torch-testing sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/testing.html#torch.testing.assert_close" title="torch.testing.assert_close"><span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_close</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch_output</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="n">onnxruntime_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">¶</a></h2>
<p>Congratulations! In this tutorial, we explored the <code class="xref py py-class docutils literal notranslate"><span class="pre">ONNXRegistry</span></code> API and
discovered how to create custom implementations for unsupported or existing ATen operators
using ONNX Script.
Finally, we leveraged ONNX Runtime to execute the model and compare the results with PyTorch,
providing us with a comprehensive understanding of handling unsupported
operators in the ONNX ecosystem.</p>
</div>
<div class="section" id="further-reading">
<h2>Further reading<a class="headerlink" href="#further-reading" title="Permalink to this heading">¶</a></h2>
<p>The list below refers to tutorials that ranges from basic examples to advanced scenarios,
not necessarily in the order they are listed.
Feel free to jump directly to specific topics of your interest or
sit tight and have fun going through all of them to learn all there is about the ONNX exporter.</p>
<div class="line-block">
<div class="line">1. <a class="reference external" href="export_simple_model_to_onnx_tutorial.html">Exporting a PyTorch model to ONNX</a></div>
<div class="line">2. <a class="reference external" href="onnx_registry_tutorial.html">Extending the ONNX registry</a></div>
</div>
<div class="toctree-wrapper compound">
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.527 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-onnx-onnx-registry-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/94896e8c36969aff0b2abe5e3848a487/onnx_registry_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">onnx_registry_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0bd6b9a8e47e1d64e4d20ef356a6095d/onnx_registry_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">onnx_registry_tutorial.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<hr class="rating-hr hr-top"/>
<div class="rating-container">
<div class="rating-prompt">Rate this Tutorial</div>
<div class="stars-outer">
<i class="far fa-star" data-behavior="tutorial-rating" data-count="1" title="1 Star"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="2" title="2 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="3" title="3 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="4" title="4 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="5" title="5 Stars"></i>
</div>
</div>
<hr class="rating-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2024, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Extending the ONNX Registry</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#unsupported-aten-operators">Unsupported ATen operators</a></li>
<li><a class="reference internal" href="#custom-operators-with-existing-onnx-runtime-support">Custom operators with existing ONNX Runtime support</a></li>
<li><a class="reference internal" href="#custom-operators-without-onnx-runtime-support">Custom operators without ONNX Runtime support</a><ul>
<li><a class="reference internal" href="#custom-ops-registration-in-pytorch-fx-graph-beta">Custom Ops Registration in PyTorch FX Graph (Beta)</a></li>
<li><a class="reference internal" href="#custom-ops-registration-in-onnx-registry">Custom Ops Registration in ONNX Registry</a></li>
<li><a class="reference internal" href="#custom-ops-registration-in-onnx-runtime">Custom Ops Registration in ONNX Runtime</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#further-reading">Further reading</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js" type="text/javascript"></script>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script>
<script src="../../_static/underscore.js"></script>
<script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../_static/doctools.js"></script>
<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>
<script src="../../_static/katex.min.js"></script>
<script src="../../_static/auto-render.min.js"></script>
<script src="../../_static/katex_autorenderer.js"></script>
<script src="../../_static/design-tabs.js"></script>
<script src="../../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });

    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Mobile'];
</script>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">Stay up to date</li>
<li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">PyTorch Podcasts</li>
<li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
<li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
<li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
</ul>
</div>
</div>
<div class="privacy-policy">
<ul>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
<li class="privacy-policy-links">|</li>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
</ul>
</div>
<div class="copyright">
<p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../../_static/images/pytorch-x.svg"/>
</div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li class="resources-mobile-menu-title">
            Docs
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
</li>
<li>
<a href="https://pytorch.org/text/stable/index.html">torchtext</a>
</li>
<li>
<a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
</li>
<li>
<a href="https://pytorch.org/torcharrow">torcharrow</a>
</li>
<li>
<a href="https://pytorch.org/data">TorchData</a>
</li>
<li>
<a href="https://pytorch.org/torchrec">TorchRec</a>
</li>
<li>
<a href="https://pytorch.org/serve/">TorchServe</a>
</li>
<li>
<a href="https://pytorch.org/torchx/">TorchX</a>
</li>
<li>
<a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
            Resources
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/features">About</a>
</li>
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/#community-module">Community</a>
</li>
<li>
<a href="https://pytorch.org/community-stories">Community Stories</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/hub">Models (Beta)</a>
</li>
</ul>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>